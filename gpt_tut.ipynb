{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ca2Z08vpqfJ"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai langchain==0.0.99rc0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne-Qg0YiqA75"
      },
      "source": [
        "## Basics with OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5b0ALlsp8Eh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key =''\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYvl1FGPrMNn"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello what kind of assistant are you?\"},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch7hAIq3rRLo",
        "outputId": "f9ec3e07-9eaf-4780-8ed0-fba0b2caeb9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-6pakUtAnnDzKpBkh2QcxLAp1ymTtR at 0x7fdae98f9400> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"I am a virtual assistant, equipped with AI technology to assist you with various tasks and answer your questions as best as I can. How may I assist you today?\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1677754010,\n",
              "  \"id\": \"chatcmpl-6pakUtAnnDzKpBkh2QcxLAp1ymTtR\",\n",
              "  \"model\": \"gpt-3.5-turbo-0301\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 35,\n",
              "    \"prompt_tokens\": 26,\n",
              "    \"total_tokens\": 61\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAGcCgZkxbmy"
      },
      "source": [
        "## ChatGPT with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDQfHX6AwYea",
        "outputId": "13da4630-5237-4665-d800-a1b3cdfe38d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.99rc0\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: aiohttp, aleph-alpha-client, dataclasses-json, deeplake, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZXeJzHGxgOw"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI, OpenAIChat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-00Nk5704vL"
      },
      "outputs": [],
      "source": [
        "prefix_messages = [{\"role\": \"system\", \"content\": \"You are a helpful history professor named Kate.\"}]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygQ3pfROxyhW"
      },
      "outputs": [],
      "source": [
        "## old way\n",
        "# llm = OpenAI(model_name=\"text-davinci-003\",\n",
        "#              temperature=0, )\n",
        "\n",
        "## New way\n",
        "llm = OpenAIChat(model_name='gpt-3.5-turbo', \n",
        "             temperature=0, \n",
        "             prefix_messages=prefix_messages,\n",
        "             max_tokens = 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkX7ybjFFHkn"
      },
      "outputs": [],
      "source": [
        "\n",
        "template = \"\"\"Take the following question: {user_input}\n",
        "\n",
        "Answer it in an informative and intersting but conscise way for someone who is new to this topic.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, \n",
        "                        input_variables=[\"user_input\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "U0wSCoNvFNI9",
        "outputId": "78b85cb6-231c-4821-ac5d-41563ab0413e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Marcus Aurelius was the emperor of Rome from 161 to 180 AD. He was known for his philosophical writings, particularly his book \"Meditations,\" which is still studied today. During his reign, he faced challenges such as wars with Germanic tribes and a devastating plague. Despite these difficulties, he is remembered as one of Rome\\'s \"Five Good Emperors\" for his efforts to improve the lives of his subjects and his commitment to justice and virtue.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "user_input = \"When was Marcus Aurelius the emperor of Rome?\"\n",
        "\n",
        "llm_chain.run(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "WOlKi88W2SsJ",
        "outputId": "e2de79e5-b366-4899-82a0-d2c7780e5dde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Marcus Aurelius was married to a woman named Faustina the Younger. She was the daughter of Antoninus Pius, who was the emperor before Marcus Aurelius. Faustina was known for her beauty and intelligence, and she was a devoted wife to Marcus Aurelius. However, there were rumors that she was unfaithful to him, which caused him great distress. Despite this, Marcus Aurelius remained loyal to her and even deified her after her death.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "user_input = \"Who was Marcus Aurelius married to?\"\n",
        "\n",
        "llm_chain.run(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reuPLunX3sEm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
